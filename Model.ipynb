{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlG3riHjEZIS",
        "outputId": "97ef77c4-ca52-4082-eeaf-4e6ab534529f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training data:\n",
            "project_is_approved\n",
            "1    0.849184\n",
            "0    0.150816\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 7652  5529]\n",
            " [29480 44737]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.58      0.30     13181\n",
            "           1       0.89      0.60      0.72     74217\n",
            "\n",
            "    accuracy                           0.60     87398\n",
            "   macro avg       0.55      0.59      0.51     87398\n",
            "weighted avg       0.79      0.60      0.66     87398\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "\n",
        "# Display class distribution\n",
        "print(\"Class distribution in training data:\")\n",
        "print(train_data['project_is_approved'].value_counts(normalize=True))\n",
        "\n",
        "# Preprocess function to handle both train and test data\n",
        "def preprocess_data(data):\n",
        "    # Handling missing values\n",
        "    data['teacher_prefix'].fillna(data['teacher_prefix'].mode()[0], inplace=True)\n",
        "    # Drop columns that won't be used in the model\n",
        "    data.drop(columns=['project_essay_3', 'project_essay_4', 'teacher_id', 'project_title', 'project_essay_1', 'project_essay_2', 'project_resource_summary'], inplace=True)\n",
        "    # Convert 'project_submitted_datetime' to datetime and extract features\n",
        "    data['project_submitted_datetime'] = pd.to_datetime(data['project_submitted_datetime'])\n",
        "    data['submission_month'] = data['project_submitted_datetime'].dt.month\n",
        "    data['submission_day'] = data['project_submitted_datetime'].dt.day\n",
        "    data['submission_hour'] = data['project_submitted_datetime'].dt.hour\n",
        "    data.drop('project_submitted_datetime', axis=1, inplace=True)\n",
        "    # One-hot encoding\n",
        "    categorical_cols = ['teacher_prefix', 'school_state', 'project_grade_category', 'project_subject_categories', 'project_subject_subcategories']\n",
        "    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "    return data\n",
        "\n",
        "# Process training data\n",
        "train_data_processed = preprocess_data(train_data.copy())\n",
        "\n",
        "# Separate features and target\n",
        "X_train = train_data_processed.drop('project_is_approved', axis=1)\n",
        "y_train = train_data_processed['project_is_approved']\n",
        "\n",
        "# Oversampling to handle class imbalance\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train a logistic regression model with class weight balanced\n",
        "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Load and process the test data\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "test_data_processed = preprocess_data(test_data.copy())\n",
        "# Align test data features with training data features\n",
        "test_data_processed = test_data_processed.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = model.predict(test_data_processed)\n",
        "\n",
        "# Save predictions to CSV file\n",
        "submission = pd.DataFrame(test_predictions, columns=['predicted_label'])\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Predict_SE22UARI117', index=False)\n",
        "\n",
        "# Evaluate model\n",
        "y_val_pred = model.predict(X_train)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_val_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_train, y_val_pred))\n"
      ]
    }
  ]
}